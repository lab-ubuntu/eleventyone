---
title: Por que Ubuntu_Labe?
date: 2020-06-01
---

## Saiba mais sobre a história do nosso projeto.

Em 2016, Tay, o robô digital desenvolvido pela microsoft para interagir no twitter com jovens de 18 a 24 anos através de um sistema de inteligência artificial, foi retirado do ar em menos de 24 horas por assumir uma postura racista. Tay foi desenvolvido para aprender com as postagens de diversos usuários da rede social e começar a produzir conteúdo direcionado ao seu público alvo. Tay foi um sucesso em seus testes de laboratório por conseguir uma coerência semelhante a um humano, mas falhou absurdamente ao ignorar que o conteúdo da internet pode ser abusivo e reproduzir de forma indiscriminada uma lógica desigual enraizada na história do mundo.
Tay não é o único exemplo de reprodução tecnológico do viés de desigualdade social. Em 2019, a Google pediu desculpas publicamente por seu sistema de classificação de imagens por identificar um casal de pessoas negras como gorilas e, em 2018, a Amazon encerrou a sua ferramenta de recrutamento online por privilegiar candidatos do sexo masculino. Estes são apenas alguns dos muitos exemplos descobertos até agora de aplicativos de inteligência artificial (AI) que discriminam sistematicamente populações específicas.
Numa sociedade que caminha no sentido da sua tecnologia, erros de aprendizado de algoritmos como estes não são apenas ofensivos, mas principalmente, promotores da desigualdade. Isto porque, cada vez mais, os computadores são encarregados de tomar decisões cruciais e muitas vezes com base numa imparcialidade que passa despercebida. Em outras palavras, a inteligência artificial está cada vez mais presente nas nossas vidas cotidianas sendo usada para alimentar políticas de segurança pública, aprovação de empréstimos ou seleções de empregos e, nesse contexto, a emergência de falhas derivadas da simples replicação de tecnologias que desconsideram as desigualdades raciais podem implicar em decisões discriminatórias.
